{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "354ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryF1Score, BinaryConfusionMatrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# 1. Load data\n",
    "data_folder = \"Pre-Processed Dark-Eyed Junco Data/\"\n",
    "env = pd.read_csv(data_folder + \"environmental_vars_checklists_md_jan.csv\")\n",
    "checklists = pd.read_csv(data_folder + \"checklists_zf_md_deju_jan.csv\")\n",
    "train_df = pd.merge(checklists, env, on=\"checklist_id\")\n",
    "\n",
    "features = ['year', 'day_of_year', 'hours_of_day',\n",
    "            'effort_hours', 'effort_distance_km', 'effort_speed_kmph',\n",
    "            'number_observers'] + \\\n",
    "           [col for col in train_df.columns if col.startswith(('pland_', 'ed_', 'elevation_'))]\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df['species_observed'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf81ed",
   "metadata": {},
   "source": [
    "## Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3060d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1226.8562\n",
      "Best threshold: 0.404, MCC: 0.343, F1: 0.614\n",
      "Epoch 2, Loss: 1177.0269\n",
      "Best threshold: 0.434, MCC: 0.367, F1: 0.616\n",
      "Epoch 3, Loss: 1153.0006\n",
      "Best threshold: 0.495, MCC: 0.387, F1: 0.607\n",
      "Epoch 4, Loss: 1132.5621\n",
      "Best threshold: 0.455, MCC: 0.387, F1: 0.616\n",
      "Epoch 5, Loss: 1114.6190\n",
      "Best threshold: 0.434, MCC: 0.405, F1: 0.650\n",
      "Epoch 6, Loss: 1099.2095\n",
      "Best threshold: 0.394, MCC: 0.413, F1: 0.665\n",
      "Epoch 7, Loss: 1086.0940\n",
      "Best threshold: 0.414, MCC: 0.421, F1: 0.656\n",
      "Epoch 8, Loss: 1076.0248\n",
      "Best threshold: 0.384, MCC: 0.426, F1: 0.670\n",
      "Epoch 9, Loss: 1066.6989\n",
      "Best threshold: 0.444, MCC: 0.428, F1: 0.653\n",
      "Epoch 10, Loss: 1057.6799\n",
      "Best threshold: 0.515, MCC: 0.437, F1: 0.645\n",
      "Epoch 11, Loss: 1049.9668\n",
      "Best threshold: 0.515, MCC: 0.436, F1: 0.643\n",
      "Epoch 12, Loss: 1042.0788\n",
      "Best threshold: 0.465, MCC: 0.447, F1: 0.665\n",
      "Epoch 13, Loss: 1034.8003\n",
      "Best threshold: 0.505, MCC: 0.436, F1: 0.648\n",
      "Epoch 14, Loss: 1029.6375\n",
      "Best threshold: 0.414, MCC: 0.445, F1: 0.675\n",
      "Epoch 15, Loss: 1023.1354\n",
      "Best threshold: 0.465, MCC: 0.444, F1: 0.653\n",
      "Epoch 16, Loss: 1016.8419\n",
      "Best threshold: 0.495, MCC: 0.448, F1: 0.656\n",
      "Epoch 17, Loss: 1010.9116\n",
      "Best threshold: 0.444, MCC: 0.452, F1: 0.674\n",
      "Epoch 18, Loss: 1005.9454\n",
      "Best threshold: 0.495, MCC: 0.453, F1: 0.656\n",
      "Epoch 19, Loss: 1000.7996\n",
      "Best threshold: 0.455, MCC: 0.456, F1: 0.666\n",
      "Epoch 20, Loss: 994.0313\n",
      "Best threshold: 0.444, MCC: 0.449, F1: 0.666\n",
      "Epoch 21, Loss: 991.3810\n",
      "Best threshold: 0.455, MCC: 0.454, F1: 0.668\n",
      "Epoch 22, Loss: 986.4136\n",
      "Best threshold: 0.455, MCC: 0.451, F1: 0.675\n",
      "Epoch 23, Loss: 983.3275\n",
      "Best threshold: 0.414, MCC: 0.451, F1: 0.675\n",
      "Epoch 24, Loss: 979.8367\n",
      "Best threshold: 0.465, MCC: 0.462, F1: 0.672\n",
      "Epoch 25, Loss: 973.4179\n",
      "Best threshold: 0.414, MCC: 0.451, F1: 0.680\n",
      "Epoch 26, Loss: 972.4148\n",
      "Best threshold: 0.414, MCC: 0.457, F1: 0.678\n",
      "Epoch 27, Loss: 966.9888\n",
      "Best threshold: 0.465, MCC: 0.463, F1: 0.666\n",
      "Epoch 28, Loss: 962.5171\n",
      "Best threshold: 0.434, MCC: 0.457, F1: 0.672\n",
      "Epoch 29, Loss: 960.8620\n",
      "Best threshold: 0.485, MCC: 0.463, F1: 0.668\n",
      "Epoch 30, Loss: 957.3014\n",
      "Best threshold: 0.434, MCC: 0.467, F1: 0.679\n",
      "Epoch 31, Loss: 952.1059\n",
      "Best threshold: 0.465, MCC: 0.465, F1: 0.674\n",
      "Epoch 32, Loss: 949.6381\n",
      "Best threshold: 0.455, MCC: 0.461, F1: 0.674\n",
      "Epoch 33, Loss: 944.9646\n",
      "Best threshold: 0.444, MCC: 0.462, F1: 0.676\n",
      "Epoch 34, Loss: 941.6183\n",
      "Best threshold: 0.444, MCC: 0.458, F1: 0.670\n",
      "Epoch 35, Loss: 941.1183\n",
      "Best threshold: 0.455, MCC: 0.460, F1: 0.674\n",
      "Epoch 36, Loss: 936.5096\n",
      "Best threshold: 0.495, MCC: 0.462, F1: 0.664\n",
      "Epoch 37, Loss: 935.0036\n",
      "Best threshold: 0.444, MCC: 0.457, F1: 0.675\n",
      "Epoch 38, Loss: 930.7529\n",
      "Best threshold: 0.505, MCC: 0.455, F1: 0.664\n",
      "Epoch 39, Loss: 928.0076\n",
      "Best threshold: 0.455, MCC: 0.460, F1: 0.676\n",
      "Epoch 40, Loss: 926.1097\n",
      "Best threshold: 0.505, MCC: 0.457, F1: 0.662\n",
      "Epoch 41, Loss: 922.8411\n",
      "Best threshold: 0.455, MCC: 0.456, F1: 0.675\n",
      "Epoch 42, Loss: 920.8050\n",
      "Best threshold: 0.424, MCC: 0.462, F1: 0.682\n",
      "Epoch 43, Loss: 918.7956\n",
      "Best threshold: 0.515, MCC: 0.457, F1: 0.656\n",
      "Epoch 44, Loss: 915.6201\n",
      "Best threshold: 0.444, MCC: 0.453, F1: 0.669\n",
      "Epoch 45, Loss: 912.8138\n",
      "Best threshold: 0.434, MCC: 0.463, F1: 0.683\n",
      "Epoch 46, Loss: 910.9583\n",
      "Best threshold: 0.455, MCC: 0.466, F1: 0.675\n",
      "Epoch 47, Loss: 909.9266\n",
      "Best threshold: 0.515, MCC: 0.460, F1: 0.661\n",
      "Epoch 48, Loss: 905.8229\n",
      "Best threshold: 0.475, MCC: 0.461, F1: 0.672\n",
      "Epoch 49, Loss: 905.2001\n",
      "Best threshold: 0.455, MCC: 0.461, F1: 0.673\n",
      "Epoch 50, Loss: 900.9011\n",
      "Best threshold: 0.535, MCC: 0.467, F1: 0.661\n",
      "Epoch 51, Loss: 898.1642\n",
      "Best threshold: 0.455, MCC: 0.465, F1: 0.678\n",
      "Epoch 52, Loss: 896.9933\n",
      "Best threshold: 0.535, MCC: 0.463, F1: 0.667\n",
      "Epoch 53, Loss: 894.3767\n",
      "Best threshold: 0.424, MCC: 0.464, F1: 0.681\n",
      "Epoch 54, Loss: 893.0136\n",
      "Best threshold: 0.465, MCC: 0.469, F1: 0.676\n",
      "Epoch 55, Loss: 891.6544\n",
      "Best threshold: 0.444, MCC: 0.463, F1: 0.679\n",
      "Epoch 56, Loss: 888.7464\n",
      "Best threshold: 0.394, MCC: 0.465, F1: 0.687\n",
      "Epoch 57, Loss: 887.1848\n",
      "Best threshold: 0.525, MCC: 0.466, F1: 0.663\n",
      "Epoch 58, Loss: 884.8181\n",
      "Best threshold: 0.556, MCC: 0.462, F1: 0.656\n",
      "Epoch 59, Loss: 883.8034\n",
      "Best threshold: 0.465, MCC: 0.463, F1: 0.671\n",
      "Epoch 60, Loss: 880.6657\n",
      "Best threshold: 0.424, MCC: 0.470, F1: 0.685\n",
      "Epoch 61, Loss: 880.3916\n",
      "Best threshold: 0.434, MCC: 0.459, F1: 0.677\n",
      "Epoch 62, Loss: 877.2290\n",
      "Best threshold: 0.485, MCC: 0.456, F1: 0.672\n",
      "Epoch 63, Loss: 876.4264\n",
      "Best threshold: 0.384, MCC: 0.456, F1: 0.685\n",
      "Epoch 64, Loss: 874.3769\n",
      "Best threshold: 0.515, MCC: 0.459, F1: 0.661\n",
      "Epoch 65, Loss: 871.4221\n",
      "Best threshold: 0.485, MCC: 0.455, F1: 0.664\n",
      "Epoch 66, Loss: 870.8427\n",
      "Best threshold: 0.535, MCC: 0.455, F1: 0.658\n",
      "Epoch 67, Loss: 868.7901\n",
      "Best threshold: 0.505, MCC: 0.457, F1: 0.668\n",
      "Epoch 68, Loss: 867.1364\n",
      "Best threshold: 0.434, MCC: 0.462, F1: 0.676\n",
      "Epoch 69, Loss: 866.0221\n",
      "Best threshold: 0.566, MCC: 0.459, F1: 0.659\n",
      "Epoch 70, Loss: 865.5176\n",
      "Best threshold: 0.485, MCC: 0.460, F1: 0.669\n",
      "Epoch 71, Loss: 860.6949\n",
      "Best threshold: 0.495, MCC: 0.462, F1: 0.669\n",
      "Epoch 72, Loss: 861.6837\n",
      "Best threshold: 0.475, MCC: 0.464, F1: 0.677\n",
      "Epoch 73, Loss: 857.8526\n",
      "Best threshold: 0.515, MCC: 0.456, F1: 0.666\n",
      "Epoch 74, Loss: 858.8444\n",
      "Best threshold: 0.485, MCC: 0.461, F1: 0.668\n",
      "Epoch 75, Loss: 856.1508\n",
      "Best threshold: 0.495, MCC: 0.459, F1: 0.659\n",
      "Epoch 76, Loss: 856.2211\n",
      "Best threshold: 0.414, MCC: 0.453, F1: 0.678\n",
      "Epoch 77, Loss: 853.7471\n",
      "Best threshold: 0.465, MCC: 0.457, F1: 0.675\n",
      "Epoch 78, Loss: 850.7096\n",
      "Best threshold: 0.545, MCC: 0.462, F1: 0.661\n",
      "Epoch 79, Loss: 851.8924\n",
      "Best threshold: 0.505, MCC: 0.459, F1: 0.666\n",
      "Epoch 80, Loss: 850.9542\n",
      "Best threshold: 0.465, MCC: 0.459, F1: 0.672\n",
      "Epoch 81, Loss: 847.7642\n",
      "Best threshold: 0.404, MCC: 0.457, F1: 0.684\n",
      "Epoch 82, Loss: 847.8053\n",
      "Best threshold: 0.404, MCC: 0.458, F1: 0.681\n",
      "Epoch 83, Loss: 844.3476\n",
      "Best threshold: 0.505, MCC: 0.459, F1: 0.668\n",
      "Epoch 84, Loss: 844.9455\n",
      "Best threshold: 0.485, MCC: 0.455, F1: 0.667\n",
      "Epoch 85, Loss: 845.1547\n",
      "Best threshold: 0.455, MCC: 0.457, F1: 0.674\n",
      "Epoch 86, Loss: 842.1224\n",
      "Best threshold: 0.424, MCC: 0.463, F1: 0.679\n",
      "Epoch 87, Loss: 841.7733\n",
      "Best threshold: 0.434, MCC: 0.457, F1: 0.673\n",
      "Epoch 88, Loss: 840.2496\n",
      "Best threshold: 0.505, MCC: 0.452, F1: 0.666\n",
      "Epoch 89, Loss: 835.6596\n",
      "Best threshold: 0.505, MCC: 0.450, F1: 0.664\n",
      "Epoch 90, Loss: 833.9785\n",
      "Best threshold: 0.535, MCC: 0.451, F1: 0.650\n",
      "Epoch 91, Loss: 834.4277\n",
      "Best threshold: 0.465, MCC: 0.451, F1: 0.665\n",
      "Epoch 92, Loss: 834.5654\n",
      "Best threshold: 0.424, MCC: 0.458, F1: 0.681\n",
      "Epoch 93, Loss: 833.1319\n",
      "Best threshold: 0.414, MCC: 0.453, F1: 0.675\n",
      "Epoch 94, Loss: 832.2997\n",
      "Best threshold: 0.434, MCC: 0.455, F1: 0.678\n",
      "Epoch 95, Loss: 830.7380\n",
      "Best threshold: 0.414, MCC: 0.449, F1: 0.672\n",
      "Epoch 96, Loss: 829.8426\n",
      "Best threshold: 0.364, MCC: 0.455, F1: 0.684\n",
      "Epoch 97, Loss: 829.5301\n",
      "Best threshold: 0.535, MCC: 0.459, F1: 0.661\n",
      "Epoch 98, Loss: 828.2405\n",
      "Best threshold: 0.505, MCC: 0.461, F1: 0.668\n",
      "Epoch 99, Loss: 827.9176\n",
      "Best threshold: 0.434, MCC: 0.447, F1: 0.670\n",
      "Epoch 100, Loss: 826.3341\n",
      "Best threshold: 0.505, MCC: 0.451, F1: 0.664\n"
     ]
    }
   ],
   "source": [
    "# 2. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=28)\n",
    "\n",
    "# 3. Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# 4. Define the model\n",
    "class SpeciesNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SpeciesNet(X_train.shape[1]).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "accuracy = BinaryAccuracy().to(device)\n",
    "f1 = BinaryF1Score().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. Training loop\n",
    "train_accuracy = []\n",
    "train_f1 = []\n",
    "val_accuracy = []\n",
    "val_f1 = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        accuracy.update(preds.squeeze(1), yb.squeeze(1))\n",
    "        f1.update(preds.squeeze(1), yb.squeeze(1))\n",
    "    train_accuracy.append(accuracy.compute().cpu().numpy())\n",
    "    train_f1.append(f1.compute().cpu().numpy())\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    accuracy.reset()\n",
    "    f1.reset()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_probs = model(X_train_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    cal = IsotonicRegression(out_of_bounds='clip')\n",
    "    cal.fit(train_probs, y_train)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            val_probs_raw = model(X_val_tensor)\n",
    "    #         accuracy.update(val_probs_raw.squeeze(1), yb.squeeze(1))\n",
    "    #         f1.update(val_probs_raw.squeeze(1), yb.squeeze(1))\n",
    "    # val_accuracy.append(accuracy.compute().cpu().numpy())\n",
    "    # val_f1.append(f1.compute().cpu().numpy())\n",
    "\n",
    "    val_probs_cal = cal.predict(val_probs_raw.cpu().numpy().flatten())\n",
    "\n",
    "    # 7. Threshold tuning\n",
    "    best_mcc, best_f1, best_thresh = -1, -1, 0\n",
    "    for t in np.linspace(0, 1, 100):\n",
    "        preds = (val_probs_cal > t).astype(int)\n",
    "        m = matthews_corrcoef(y_val, preds)\n",
    "        f = f1_score(y_val, preds)\n",
    "        if m > best_mcc:\n",
    "            best_mcc, best_f1, best_thresh = m, f, t\n",
    "\n",
    "    print(f\"Best threshold: {best_thresh:.3f}, MCC: {best_mcc:.3f}, F1: {best_f1:.3f}\")\n",
    "    accuracy.reset()\n",
    "    f1.reset()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2300d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.505, MCC: 0.451, F1: 0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alonz\\AppData\\Local\\Temp\\ipykernel_19764\\689761987.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_output[\"in_range\"] = (grid_output[\"encounter_rate\"] > best_thresh).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict and calibrate with isotonic regression\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_probs = model(X_train_tensor).cpu().numpy().flatten()\n",
    "\n",
    "cal = IsotonicRegression(out_of_bounds='clip')\n",
    "cal.fit(train_probs, y_train)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_probs_raw = model(X_val_tensor).cpu().numpy().flatten()\n",
    "val_probs_cal = cal.predict(val_probs_raw)\n",
    "\n",
    "# 7. Threshold tuning\n",
    "best_mcc, best_f1, best_thresh = -1, -1, 0\n",
    "for t in np.linspace(0, 1, 100):\n",
    "    preds = (val_probs_cal > t).astype(int)\n",
    "    m = matthews_corrcoef(y_val, preds)\n",
    "    f = f1_score(y_val, preds)\n",
    "    if m > best_mcc:\n",
    "        best_mcc, best_f1, best_thresh = m, f, t\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.3f}, MCC: {best_mcc:.3f}, F1: {best_f1:.3f}\")\n",
    "\n",
    "## Generate Confusion matrix using tuned threshold and calibrated probabilities\n",
    "best_pred = (val_probs_cal > best_thresh).astype(int)\n",
    "confmat = confusion_matrix(y_val, best_pred, normalize = 'pred')\n",
    "\n",
    "# 8. Predict on grid\n",
    "grid = pd.read_csv(data_folder + \"environmental_vars_prediction_grid_md.csv\")\n",
    "grid[\"observation_date\"] = pd.to_datetime(\"2023-01-15\")\n",
    "grid[\"year\"] = grid[\"observation_date\"].dt.year\n",
    "grid[\"day_of_year\"] = grid[\"observation_date\"].dt.dayofyear\n",
    "grid[\"hours_of_day\"] = 7.5\n",
    "grid[\"effort_distance_km\"] = 2\n",
    "grid[\"effort_hours\"] = 1\n",
    "grid[\"effort_speed_kmph\"] = 2\n",
    "grid[\"number_observers\"] = 1\n",
    "\n",
    "X_grid = grid[features]\n",
    "X_grid_scaled = scaler.transform(X_grid)\n",
    "X_grid_tensor = torch.tensor(X_grid_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    grid_probs_raw = model(X_grid_tensor).cpu().numpy().flatten()\n",
    "grid_probs_cal = cal.predict(grid_probs_raw)\n",
    "grid[\"encounter_rate\"] = np.clip(grid_probs_cal, 0, 1)\n",
    "\n",
    "# Save outputs\n",
    "grid_output = grid[[\"cell_id\", \"x\", \"y\", \"encounter_rate\"]]\n",
    "grid_output[\"in_range\"] = (grid_output[\"encounter_rate\"] > best_thresh).astype(int)\n",
    "grid_output.to_csv(f\"junco_nn_predictions_{num_epochs}.csv\", index=False)\n",
    "\n",
    "# Save validation predictions for R\n",
    "results_df = pd.DataFrame({\n",
    "    'obs': y_val,\n",
    "    'pred': val_probs_cal\n",
    "})\n",
    "results_df.to_csv(f\"dnn_predictions_for_r_{num_epochs}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cde5b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Grid Predictions')\n",
    "plt.scatter(grid_output['x'], grid_output['y'], c = grid_output['encounter_rate'].values, s = 10, marker = 's', alpha = 0.8)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "plt.savefig(f'dnn_grid_pred_{num_epochs}.png')\n",
    "plt.close()\n",
    "sns.heatmap(confmat, annot=True, cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "plt.savefig(f'dnn_conf_mat_{num_epochs}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2332d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracy and f1\n",
    "plt.plot(range(num_epochs), train_accuracy)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "# plt.show()\n",
    "plt.savefig(f'dnn_train_accuracy_{num_epochs}.png')\n",
    "plt.close()\n",
    "plt.plot(range(num_epochs), train_f1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training F1 Score')\n",
    "# plt.show()\n",
    "plt.savefig(f'dnn_train_f1_{num_epochs}.png')\n",
    "plt.close()\n",
    "# plt.plot(range(num_epochs), val_accuracy)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.savefig('dnn_val_accuracy.png')\n",
    "# plt.close()\n",
    "# plt.plot(range(num_epochs), val_f1)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('F1 Score')\n",
    "# plt.title('Validation F1 Score')\n",
    "# plt.savefig('dnn_val_f1.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81155ad",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d9b83e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1253.3259\n",
      "Best threshold: 0.434, MCC: 0.349, F1: 0.616\n",
      "Epoch 2, Loss: 1173.7545\n",
      "Best threshold: 0.424, MCC: 0.391, F1: 0.636\n",
      "Epoch 3, Loss: 1135.8603\n",
      "Best threshold: 0.455, MCC: 0.406, F1: 0.642\n",
      "Epoch 4, Loss: 1109.6776\n",
      "Best threshold: 0.444, MCC: 0.428, F1: 0.647\n",
      "Epoch 5, Loss: 1089.1579\n",
      "Best threshold: 0.444, MCC: 0.425, F1: 0.654\n",
      "Epoch 6, Loss: 1071.8982\n",
      "Best threshold: 0.394, MCC: 0.423, F1: 0.663\n",
      "Epoch 7, Loss: 1058.0865\n",
      "Best threshold: 0.455, MCC: 0.441, F1: 0.658\n",
      "Epoch 8, Loss: 1041.8161\n",
      "Best threshold: 0.364, MCC: 0.447, F1: 0.683\n",
      "Epoch 9, Loss: 1033.4085\n",
      "Best threshold: 0.434, MCC: 0.445, F1: 0.670\n",
      "Epoch 10, Loss: 1020.2911\n",
      "Best threshold: 0.404, MCC: 0.459, F1: 0.684\n",
      "Epoch 11, Loss: 1008.7249\n",
      "Best threshold: 0.495, MCC: 0.457, F1: 0.658\n",
      "Epoch 12, Loss: 999.4656\n",
      "Best threshold: 0.455, MCC: 0.458, F1: 0.673\n",
      "Epoch 13, Loss: 987.8665\n",
      "Best threshold: 0.404, MCC: 0.458, F1: 0.683\n",
      "Epoch 14, Loss: 978.3274\n",
      "Best threshold: 0.434, MCC: 0.468, F1: 0.680\n",
      "Epoch 15, Loss: 970.1500\n",
      "Best threshold: 0.414, MCC: 0.462, F1: 0.686\n",
      "Epoch 16, Loss: 960.9964\n",
      "Best threshold: 0.434, MCC: 0.461, F1: 0.680\n",
      "Epoch 17, Loss: 950.5532\n",
      "Best threshold: 0.444, MCC: 0.463, F1: 0.680\n",
      "Epoch 18, Loss: 941.9136\n",
      "Best threshold: 0.545, MCC: 0.456, F1: 0.645\n",
      "Epoch 19, Loss: 935.2379\n",
      "Best threshold: 0.515, MCC: 0.466, F1: 0.665\n",
      "Epoch 20, Loss: 927.3518\n",
      "Best threshold: 0.434, MCC: 0.466, F1: 0.684\n",
      "Epoch 21, Loss: 917.0871\n",
      "Best threshold: 0.444, MCC: 0.462, F1: 0.672\n",
      "Epoch 22, Loss: 910.6851\n",
      "Best threshold: 0.495, MCC: 0.462, F1: 0.666\n",
      "Epoch 23, Loss: 904.1850\n",
      "Best threshold: 0.485, MCC: 0.471, F1: 0.676\n",
      "Epoch 24, Loss: 894.1844\n",
      "Best threshold: 0.485, MCC: 0.466, F1: 0.677\n",
      "Epoch 25, Loss: 888.3764\n",
      "Best threshold: 0.455, MCC: 0.456, F1: 0.668\n",
      "Epoch 26, Loss: 881.3966\n",
      "Best threshold: 0.455, MCC: 0.462, F1: 0.680\n",
      "Epoch 27, Loss: 872.0282\n",
      "Best threshold: 0.505, MCC: 0.466, F1: 0.669\n",
      "Epoch 28, Loss: 863.5894\n",
      "Best threshold: 0.424, MCC: 0.457, F1: 0.678\n",
      "Epoch 29, Loss: 859.5770\n",
      "Best threshold: 0.465, MCC: 0.453, F1: 0.670\n",
      "Epoch 30, Loss: 851.3318\n",
      "Best threshold: 0.444, MCC: 0.454, F1: 0.674\n",
      "Epoch 31, Loss: 844.3179\n",
      "Best threshold: 0.505, MCC: 0.456, F1: 0.664\n",
      "Epoch 32, Loss: 837.6336\n",
      "Best threshold: 0.384, MCC: 0.448, F1: 0.680\n",
      "Epoch 33, Loss: 832.3294\n",
      "Best threshold: 0.495, MCC: 0.447, F1: 0.664\n",
      "Epoch 34, Loss: 826.8294\n",
      "Best threshold: 0.374, MCC: 0.453, F1: 0.684\n",
      "Epoch 35, Loss: 815.5073\n",
      "Best threshold: 0.404, MCC: 0.454, F1: 0.681\n",
      "Epoch 36, Loss: 812.1451\n",
      "Best threshold: 0.424, MCC: 0.458, F1: 0.680\n",
      "Epoch 37, Loss: 804.8894\n",
      "Best threshold: 0.475, MCC: 0.446, F1: 0.670\n",
      "Epoch 38, Loss: 799.9700\n",
      "Best threshold: 0.424, MCC: 0.441, F1: 0.673\n",
      "Epoch 39, Loss: 792.1673\n",
      "Best threshold: 0.404, MCC: 0.447, F1: 0.678\n",
      "Epoch 40, Loss: 788.3804\n",
      "Best threshold: 0.434, MCC: 0.454, F1: 0.679\n",
      "Epoch 41, Loss: 782.4169\n",
      "Best threshold: 0.434, MCC: 0.452, F1: 0.676\n",
      "Epoch 42, Loss: 774.3851\n",
      "Best threshold: 0.434, MCC: 0.450, F1: 0.676\n",
      "Epoch 43, Loss: 766.0104\n",
      "Best threshold: 0.404, MCC: 0.435, F1: 0.671\n",
      "Epoch 44, Loss: 762.4617\n",
      "Best threshold: 0.354, MCC: 0.443, F1: 0.682\n",
      "Epoch 45, Loss: 757.8013\n",
      "Best threshold: 0.495, MCC: 0.444, F1: 0.660\n",
      "Epoch 46, Loss: 749.2868\n",
      "Best threshold: 0.414, MCC: 0.443, F1: 0.675\n",
      "Epoch 47, Loss: 744.1971\n",
      "Best threshold: 0.384, MCC: 0.442, F1: 0.676\n",
      "Epoch 48, Loss: 741.3338\n",
      "Best threshold: 0.404, MCC: 0.441, F1: 0.675\n",
      "Epoch 49, Loss: 735.5607\n",
      "Best threshold: 0.424, MCC: 0.442, F1: 0.666\n",
      "Epoch 50, Loss: 731.9111\n",
      "Best threshold: 0.475, MCC: 0.445, F1: 0.665\n",
      "Epoch 51, Loss: 721.1582\n",
      "Best threshold: 0.384, MCC: 0.445, F1: 0.680\n",
      "Epoch 52, Loss: 715.2114\n",
      "Best threshold: 0.414, MCC: 0.441, F1: 0.674\n",
      "Epoch 53, Loss: 714.6976\n",
      "Best threshold: 0.556, MCC: 0.444, F1: 0.655\n",
      "Epoch 54, Loss: 709.2743\n",
      "Best threshold: 0.485, MCC: 0.438, F1: 0.660\n",
      "Epoch 55, Loss: 702.2120\n",
      "Best threshold: 0.394, MCC: 0.437, F1: 0.671\n",
      "Epoch 56, Loss: 698.2742\n",
      "Best threshold: 0.333, MCC: 0.440, F1: 0.678\n",
      "Epoch 57, Loss: 691.7843\n",
      "Best threshold: 0.333, MCC: 0.433, F1: 0.676\n",
      "Epoch 58, Loss: 697.0783\n",
      "Best threshold: 0.465, MCC: 0.440, F1: 0.664\n",
      "Epoch 59, Loss: 687.3643\n",
      "Best threshold: 0.384, MCC: 0.436, F1: 0.672\n",
      "Epoch 60, Loss: 683.2410\n",
      "Best threshold: 0.505, MCC: 0.432, F1: 0.658\n",
      "Epoch 61, Loss: 675.5227\n",
      "Best threshold: 0.333, MCC: 0.428, F1: 0.672\n",
      "Epoch 62, Loss: 673.0694\n",
      "Best threshold: 0.434, MCC: 0.432, F1: 0.661\n",
      "Epoch 63, Loss: 668.4844\n",
      "Best threshold: 0.414, MCC: 0.429, F1: 0.666\n",
      "Epoch 64, Loss: 663.7294\n",
      "Best threshold: 0.384, MCC: 0.427, F1: 0.668\n",
      "Epoch 65, Loss: 659.7784\n",
      "Best threshold: 0.404, MCC: 0.433, F1: 0.667\n",
      "Epoch 66, Loss: 658.1524\n",
      "Best threshold: 0.374, MCC: 0.429, F1: 0.669\n",
      "Epoch 67, Loss: 654.5747\n",
      "Best threshold: 0.404, MCC: 0.434, F1: 0.668\n",
      "Epoch 68, Loss: 646.7979\n",
      "Best threshold: 0.343, MCC: 0.425, F1: 0.667\n",
      "Epoch 69, Loss: 646.1235\n",
      "Best threshold: 0.343, MCC: 0.422, F1: 0.668\n",
      "Epoch 70, Loss: 638.9923\n",
      "Best threshold: 0.333, MCC: 0.431, F1: 0.672\n",
      "Epoch 71, Loss: 640.4579\n",
      "Best threshold: 0.394, MCC: 0.426, F1: 0.664\n",
      "Epoch 72, Loss: 631.9487\n",
      "Best threshold: 0.374, MCC: 0.428, F1: 0.667\n",
      "Epoch 73, Loss: 635.3594\n",
      "Best threshold: 0.414, MCC: 0.425, F1: 0.663\n",
      "Epoch 74, Loss: 625.1424\n",
      "Best threshold: 0.525, MCC: 0.430, F1: 0.655\n",
      "Epoch 75, Loss: 626.2287\n",
      "Best threshold: 0.424, MCC: 0.427, F1: 0.659\n",
      "Epoch 76, Loss: 623.4342\n",
      "Best threshold: 0.364, MCC: 0.422, F1: 0.667\n",
      "Epoch 77, Loss: 617.9146\n",
      "Best threshold: 0.434, MCC: 0.425, F1: 0.657\n",
      "Epoch 78, Loss: 615.4198\n",
      "Best threshold: 0.444, MCC: 0.417, F1: 0.653\n",
      "Epoch 79, Loss: 610.6400\n",
      "Best threshold: 0.495, MCC: 0.425, F1: 0.652\n",
      "Epoch 80, Loss: 608.9539\n",
      "Best threshold: 0.495, MCC: 0.424, F1: 0.652\n",
      "Epoch 81, Loss: 606.4416\n",
      "Best threshold: 0.556, MCC: 0.425, F1: 0.647\n",
      "Epoch 82, Loss: 604.8047\n",
      "Best threshold: 0.475, MCC: 0.427, F1: 0.657\n",
      "Epoch 83, Loss: 601.9716\n",
      "Best threshold: 0.404, MCC: 0.418, F1: 0.658\n",
      "Epoch 84, Loss: 595.2776\n",
      "Best threshold: 0.384, MCC: 0.424, F1: 0.666\n",
      "Epoch 85, Loss: 596.9098\n",
      "Best threshold: 0.384, MCC: 0.419, F1: 0.662\n",
      "Epoch 86, Loss: 592.2837\n",
      "Best threshold: 0.404, MCC: 0.419, F1: 0.657\n",
      "Epoch 87, Loss: 590.2277\n",
      "Best threshold: 0.495, MCC: 0.430, F1: 0.658\n",
      "Epoch 88, Loss: 585.2468\n",
      "Best threshold: 0.515, MCC: 0.413, F1: 0.642\n",
      "Epoch 89, Loss: 583.9598\n",
      "Best threshold: 0.323, MCC: 0.421, F1: 0.668\n",
      "Epoch 90, Loss: 578.8456\n",
      "Best threshold: 0.394, MCC: 0.418, F1: 0.658\n",
      "Epoch 91, Loss: 577.3198\n",
      "Best threshold: 0.374, MCC: 0.417, F1: 0.660\n",
      "Epoch 92, Loss: 576.2729\n",
      "Best threshold: 0.374, MCC: 0.424, F1: 0.665\n",
      "Epoch 93, Loss: 574.0345\n",
      "Best threshold: 0.455, MCC: 0.418, F1: 0.655\n",
      "Epoch 94, Loss: 567.6704\n",
      "Best threshold: 0.323, MCC: 0.413, F1: 0.662\n",
      "Epoch 95, Loss: 566.3739\n",
      "Best threshold: 0.475, MCC: 0.420, F1: 0.652\n",
      "Epoch 96, Loss: 560.8188\n",
      "Best threshold: 0.394, MCC: 0.423, F1: 0.662\n",
      "Epoch 97, Loss: 566.6247\n",
      "Best threshold: 0.404, MCC: 0.415, F1: 0.656\n",
      "Epoch 98, Loss: 559.3660\n",
      "Best threshold: 0.424, MCC: 0.421, F1: 0.660\n",
      "Epoch 99, Loss: 565.1431\n",
      "Best threshold: 0.343, MCC: 0.419, F1: 0.663\n",
      "Epoch 100, Loss: 551.1482\n",
      "Best threshold: 0.444, MCC: 0.418, F1: 0.648\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SpeciesNet1DCNN(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super().__init__()\n",
    "        # 1) 1D-CNN feature extractor\n",
    "        self.cnn = nn.Sequential(\n",
    "            # in_channels=1, out_channels=16, length stays 39 (padding=1)\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),            # -> length = floor(39/2) = 19\n",
    "\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),            # -> length = floor(19/2) = 9\n",
    "        )\n",
    "        # compute flattened size after two pools\n",
    "        conv_out_len = input_length // 2 // 2    # 39→19→9\n",
    "        flattened_dim = 32 * conv_out_len        # 32 channels × length 9 = 288\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flattened_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, 39)\n",
    "        x = self.cnn(x)                 # -> (batch, 32, 9)\n",
    "        x = x.view(x.size(0), -1)       # -> (batch, 32*9)\n",
    "        return self.fc(x)               # -> (batch, 1)\n",
    "\n",
    "# ——— data prep ———\n",
    "# 2. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=28)\n",
    "# add a channel dimension of size 1:\n",
    "X_train_1d = X_train.reshape(-1, 1, 39)  \n",
    "X_val_1d   = X_val.reshape(  -1, 1, 39)\n",
    "\n",
    "# 3. Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_1d, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_1d, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds   = TensorDataset(X_val_tensor,   y_val_tensor)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32)\n",
    "\n",
    "# ——— model, loss, optimizer ———\n",
    "model = SpeciesNet1DCNN(input_length=39).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "accuracy = BinaryAccuracy().to(device)\n",
    "f1 = BinaryF1Score().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. Training loop\n",
    "train_accuracy = []\n",
    "train_f1 = []\n",
    "val_accuracy = []\n",
    "val_f1 = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        accuracy.update(preds.squeeze(1), yb.squeeze(1))\n",
    "        f1.update(preds.squeeze(1), yb.squeeze(1))\n",
    "    train_accuracy.append(accuracy.compute().cpu().numpy())\n",
    "    train_f1.append(f1.compute().cpu().numpy())\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    accuracy.reset()\n",
    "    f1.reset()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_probs = model(X_train_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    cal = IsotonicRegression(out_of_bounds='clip')\n",
    "    cal.fit(train_probs, y_train)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            val_probs_raw = model(X_val_tensor)\n",
    "    #         accuracy.update(val_probs_raw.squeeze(1), yb.squeeze(1))\n",
    "    #         f1.update(val_probs_raw.squeeze(1), yb.squeeze(1))\n",
    "    # val_accuracy.append(accuracy.compute().cpu().numpy())\n",
    "    # val_f1.append(f1.compute().cpu().numpy())\n",
    "\n",
    "    val_probs_cal = cal.predict(val_probs_raw.cpu().numpy().flatten())\n",
    "\n",
    "    # 7. Threshold tuning\n",
    "    best_mcc, best_f1, best_thresh = -1, -1, 0\n",
    "    for t in np.linspace(0, 1, 100):\n",
    "        preds = (val_probs_cal > t).astype(int)\n",
    "        m = matthews_corrcoef(y_val, preds)\n",
    "        f = f1_score(y_val, preds)\n",
    "        if m > best_mcc:\n",
    "            best_mcc, best_f1, best_thresh = m, f, t\n",
    "\n",
    "    print(f\"Best threshold: {best_thresh:.3f}, MCC: {best_mcc:.3f}, F1: {best_f1:.3f}\")\n",
    "    accuracy.reset()\n",
    "    f1.reset()\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d035750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.450, MCC: 0.418, F1: 0.648\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict and calibrate with isotonic regression\n",
    "model.eval()\n",
    "\n",
    "# ——— get train probs ———\n",
    "with torch.no_grad():\n",
    "    train_probs = model(X_train_tensor).cpu().numpy().flatten()\n",
    "\n",
    "cal = IsotonicRegression(out_of_bounds='clip')\n",
    "cal.fit(train_probs, y_train)\n",
    "\n",
    "# ——— get val probs ———\n",
    "with torch.no_grad():\n",
    "    val_probs_raw = model(X_val_tensor).cpu().numpy().flatten()\n",
    "val_probs_cal = cal.predict(val_probs_raw)\n",
    "\n",
    "# 7. Threshold tuning on validation set\n",
    "best_mcc, best_f1, best_thresh = -1, -1, 0.0\n",
    "for t in np.linspace(0, 1, 101):\n",
    "    preds_t = (val_probs_cal > t).astype(int)\n",
    "    m = matthews_corrcoef(y_val, preds_t)\n",
    "    f = f1_score(y_val, preds_t)\n",
    "    if m > best_mcc:\n",
    "        best_mcc, best_f1, best_thresh = m, f, t\n",
    "\n",
    "print(f\"Best threshold: {best_thresh:.3f}, MCC: {best_mcc:.3f}, F1: {best_f1:.3f}\")\n",
    "\n",
    "## Generate Confusion matrix using tuned threshold and calibrated probabilities\n",
    "best_pred = (val_probs_cal > best_thresh).astype(int)\n",
    "confmat = confusion_matrix(y_val, best_pred, normalize = 'pred')\n",
    "\n",
    "# 8. Predict on grid\n",
    "grid = pd.read_csv(data_folder + \"environmental_vars_prediction_grid_md.csv\")\n",
    "grid[\"observation_date\"] = pd.to_datetime(\"2023-01-15\")\n",
    "grid[\"year\"]           = grid[\"observation_date\"].dt.year\n",
    "grid[\"day_of_year\"]    = grid[\"observation_date\"].dt.dayofyear\n",
    "grid[\"hours_of_day\"]   = 7.5\n",
    "grid[\"effort_distance_km\"] = 2\n",
    "grid[\"effort_hours\"]       = 1\n",
    "grid[\"effort_speed_kmph\"]  = 2\n",
    "grid[\"number_observers\"]   = 1\n",
    "\n",
    "# select & scale features\n",
    "X_grid = grid[features]\n",
    "X_grid_scaled = scaler.transform(X_grid)\n",
    "\n",
    "# reshape for 1D-CNN: (N, 39) -> (N, 1, 39)\n",
    "X_grid_1d = X_grid_scaled.reshape(-1, 1, X_grid_scaled.shape[1])\n",
    "X_grid_tensor = torch.tensor(X_grid_1d, dtype=torch.float32).to(device)\n",
    "\n",
    "# Batch grid code:\n",
    "# grid_ds    = TensorDataset(X_grid_tensor)\n",
    "# grid_loader= DataLoader(grid_ds, batch_size=1024, shuffle=False)\n",
    "# grid_probs_raw = []\n",
    "# with torch.no_grad():\n",
    "#     for (xb,) in grid_loader:\n",
    "#         grid_probs_raw.append(model(xb).cpu().numpy().flatten())\n",
    "# grid_probs_raw = np.concatenate(grid_probs_raw)\n",
    "\n",
    "with torch.no_grad():\n",
    "    grid_probs_raw = model(X_grid_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# calibrate & clip\n",
    "grid_probs_cal = cal.predict(grid_probs_raw)\n",
    "grid[\"encounter_rate\"] = np.clip(grid_probs_cal, 0, 1)\n",
    "\n",
    "# assemble & save\n",
    "grid_output = grid[[\"cell_id\", \"x\", \"y\", \"encounter_rate\"]].copy()\n",
    "grid_output[\"in_range\"] = (grid_output[\"encounter_rate\"] > best_thresh).astype(int)\n",
    "grid_output.to_csv(f\"junco_cnn_predictions_{num_epochs}.csv\", index=False)\n",
    "\n",
    "# also save validation predictions for R\n",
    "results_df = pd.DataFrame({\n",
    "    'obs':  y_val,\n",
    "    'pred': val_probs_cal\n",
    "})\n",
    "results_df.to_csv(f\"cnn_predictions_for_r_{num_epochs}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "87ee7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Grid Predictions')\n",
    "plt.scatter(grid_output['x'], grid_output['y'], c = grid_output['encounter_rate'].values, s = 10, marker = 's', alpha = 0.8)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "plt.savefig(f'cnn_grid_pred_{num_epochs}.png')\n",
    "plt.close()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confmat, annot=True, cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "plt.savefig(f'cnn_conf_mat_{num_epochs}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3936394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracy and f1\n",
    "plt.plot(range(num_epochs), train_accuracy)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "# plt.show()\n",
    "plt.savefig(f'cnn_train_accuracy_{num_epochs}.png')\n",
    "plt.close()\n",
    "plt.plot(range(num_epochs), train_f1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training F1 Score')\n",
    "# plt.show()\n",
    "plt.savefig(f'cnn_train_f1_{num_epochs}.png')\n",
    "plt.close()\n",
    "# plt.plot(range(num_epochs), val_accuracy)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.savefig('cnn_val_accuracy.png')\n",
    "# plt.close()\n",
    "# plt.plot(range(num_epochs), val_f1)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('F1 Score')\n",
    "# plt.title('Validation F1 Score')\n",
    "# plt.savefig('cnn_val_f1.png')\n",
    "# plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
