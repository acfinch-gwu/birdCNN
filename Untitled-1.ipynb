{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27d1eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import fiona\n",
    "import sklearn.model_selection as model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import torcheval.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"Pre-Processed Dark-Eyed Junco Data/\"\n",
    "\n",
    "checklist_zf = pd.read_csv(data_folder + 'checklists_zf_md_deju_jan.csv', index_col = 'checklist_id', nrows = 1000)\n",
    "env_checklist = pd.read_csv(data_folder + 'environmental_vars_checklists_md_jan.csv', index_col = 'checklist_id', nrows = 1000)\n",
    "env_prediction_grid = pd.read_csv(data_folder + 'environmental_vars_prediction_grid_md.csv')\n",
    "layer_names = fiona.listlayers(data_folder + 'gis-data.gpkg')\n",
    "gis_layers = {layer: gpd.read_file(data_folder + 'gis-data.gpkg', layer = layer) for layer in layer_names}\n",
    "with rasterio.open(data_folder + 'prediction_grid_md.tif') as src:\n",
    "    grid_array = src.read(1)\n",
    "    prediction_grid = pd.DataFrame(grid_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48969839",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c6b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTIPOLYGON (((-132.89307 54.14077, -132.9914...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry\n",
       "0  MULTIPOLYGON (((-132.89307 54.14077, -132.9914..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if src.transform:\n",
    "#     cols, rows = np.meshgrid(np.arange(prediction_grid.shape[1]), np.arange(prediction_grid.shape[0]))\n",
    "#     x, y = src.transform * (cols, rows)\n",
    "#     prediction_grid['x'] = x.flatten()\n",
    "#     prediction_grid['y'] = y.flatten()\n",
    "#     prediction_grid = prediction_grid[['x', 'y', 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70453d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  checklist_id observer_id   type  observation_count  species_observed  \\\n",
      "0    S21144361  obsr145749   test               12.0              True   \n",
      "1    S21223704  obsr358359  train                8.0              True   \n",
      "2    S21568350   obsr36330  train                0.0             False   \n",
      "3    S21379010   obsr36330   test                0.0             False   \n",
      "4    S21396728   obsr36330  train                0.0             False   \n",
      "5    S21319445   obsr36330  train                3.0              True   \n",
      "6    S21534954  obsr349140  train                0.0             False   \n",
      "7    S21598685  obsr349140   test                0.0             False   \n",
      "8    S21386465  obsr414797  train                0.0             False   \n",
      "9    S21330992  obsr293603  train                0.0             False   \n",
      "\n",
      "  state_code locality_id   latitude  longitude protocol_type  \\\n",
      "0      US-MD    L1925233  39.291564 -76.818772     Traveling   \n",
      "1      US-MD    L1925870  39.071241 -76.549682    Stationary   \n",
      "2      US-MD     L192824  39.066803 -77.329510    Stationary   \n",
      "3      US-MD     L192824  39.066803 -77.329510    Stationary   \n",
      "4      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "5      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "6      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "7      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "8      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "9      US-MD     L192824  39.066803 -77.329510     Traveling   \n",
      "\n",
      "   all_species_reported observation_date  year  day_of_year  hours_of_day  \\\n",
      "0                  True       2015-01-02  2015            2     10.500000   \n",
      "1                  True       2015-01-06  2015            6     13.750000   \n",
      "2                  True       2015-01-27  2015           27     14.733333   \n",
      "3                  True       2015-01-17  2015           17      8.216667   \n",
      "4                  True       2015-01-18  2015           18     10.433333   \n",
      "5                  True       2015-01-12  2015           12     14.050000   \n",
      "6                  True       2015-01-25  2015           25      8.250000   \n",
      "7                  True       2015-01-29  2015           29     15.750000   \n",
      "8                  True       2015-01-17  2015           17     14.500000   \n",
      "9                  True       2015-01-13  2015           13     10.533333   \n",
      "\n",
      "   effort_hours  effort_distance_km  effort_speed_kmph  number_observers  \n",
      "0      0.750000               0.644           0.858667                 1  \n",
      "1      0.500000               0.000           0.000000                 1  \n",
      "2      0.383333               0.000           0.000000                 1  \n",
      "3      1.000000               0.000           0.000000                 1  \n",
      "4      1.066667               0.161           0.150938                 1  \n",
      "5      0.466667               0.161           0.345000                 1  \n",
      "6      0.333333               0.161           0.483000                 1  \n",
      "7      0.750000               1.931           2.574667                 1  \n",
      "8      1.500000               2.253           1.502000                 1  \n",
      "9      0.400000               0.080           0.200000                 1  \n",
      "(82784, 19)\n"
     ]
    }
   ],
   "source": [
    "print(checklist_zf.head(10))\n",
    "print(checklist_zf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7ee94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  checklist_id  elevation_mean  elevation_sd  ed_c00_water  pland_c00_water  \\\n",
      "0    S21144361      130.517303      8.637477      0.000000         0.000000   \n",
      "1    S21223704       12.751621      6.732613      2.569487         9.523810   \n",
      "2    S21568350       76.296135     22.626635      6.166770        14.285714   \n",
      "3    S21379010       76.296135     22.626635      6.166770        14.285714   \n",
      "4    S21396728       76.296135     22.626635      6.166770        14.285714   \n",
      "5    S21319445       76.296135     22.626635      6.166770        14.285714   \n",
      "6    S21534954       76.296135     22.626635      6.166770        14.285714   \n",
      "7    S21598685       76.296135     22.626635      6.166770        14.285714   \n",
      "8    S21386465       76.296135     22.626635      6.166770        14.285714   \n",
      "9    S21330992       76.296135     22.626635      6.166770        14.285714   \n",
      "\n",
      "   ed_c01_evergreen_needleleaf  pland_c01_evergreen_needleleaf  \\\n",
      "0                          0.0                             0.0   \n",
      "1                          0.0                             0.0   \n",
      "2                          0.0                             0.0   \n",
      "3                          0.0                             0.0   \n",
      "4                          0.0                             0.0   \n",
      "5                          0.0                             0.0   \n",
      "6                          0.0                             0.0   \n",
      "7                          0.0                             0.0   \n",
      "8                          0.0                             0.0   \n",
      "9                          0.0                             0.0   \n",
      "\n",
      "   ed_c02_evergreen_broadleaf  pland_c02_evergreen_broadleaf  \\\n",
      "0                           0                              0   \n",
      "1                           0                              0   \n",
      "2                           0                              0   \n",
      "3                           0                              0   \n",
      "4                           0                              0   \n",
      "5                           0                              0   \n",
      "6                           0                              0   \n",
      "7                           0                              0   \n",
      "8                           0                              0   \n",
      "9                           0                              0   \n",
      "\n",
      "   ed_c03_deciduous_needleleaf  ...  ed_c10_grassland  pland_c10_grassland  \\\n",
      "0                            0  ...          0.000000             0.000000   \n",
      "1                            0  ...          5.138975             9.523810   \n",
      "2                            0  ...          3.083385             4.761905   \n",
      "3                            0  ...          3.083385             4.761905   \n",
      "4                            0  ...          3.083385             4.761905   \n",
      "5                            0  ...          3.083385             4.761905   \n",
      "6                            0  ...          3.083385             4.761905   \n",
      "7                            0  ...          3.083385             4.761905   \n",
      "8                            0  ...          3.083385             4.761905   \n",
      "9                            0  ...          3.083385             4.761905   \n",
      "\n",
      "   ed_c12_cropland  pland_c12_cropland  ed_c13_urban  pland_c13_urban  \\\n",
      "0              0.0                 0.0     12.333540        73.809524   \n",
      "1              0.0                 0.0      8.736257        59.523810   \n",
      "2              0.0                 0.0      0.000000         0.000000   \n",
      "3              0.0                 0.0      0.000000         0.000000   \n",
      "4              0.0                 0.0      0.000000         0.000000   \n",
      "5              0.0                 0.0      0.000000         0.000000   \n",
      "6              0.0                 0.0      0.000000         0.000000   \n",
      "7              0.0                 0.0      0.000000         0.000000   \n",
      "8              0.0                 0.0      0.000000         0.000000   \n",
      "9              0.0                 0.0      0.000000         0.000000   \n",
      "\n",
      "   ed_c15_nonvegetated  pland_c15_nonvegetated  ed_c255_unclassified  \\\n",
      "0                  0.0                     0.0                     0   \n",
      "1                  0.0                     0.0                     0   \n",
      "2                  0.0                     0.0                     0   \n",
      "3                  0.0                     0.0                     0   \n",
      "4                  0.0                     0.0                     0   \n",
      "5                  0.0                     0.0                     0   \n",
      "6                  0.0                     0.0                     0   \n",
      "7                  0.0                     0.0                     0   \n",
      "8                  0.0                     0.0                     0   \n",
      "9                  0.0                     0.0                     0   \n",
      "\n",
      "   pland_c255_unclassified  \n",
      "0                        0  \n",
      "1                        0  \n",
      "2                        0  \n",
      "3                        0  \n",
      "4                        0  \n",
      "5                        0  \n",
      "6                        0  \n",
      "7                        0  \n",
      "8                        0  \n",
      "9                        0  \n",
      "\n",
      "[10 rows x 33 columns]\n",
      "(82784, 33)\n"
     ]
    }
   ],
   "source": [
    "print(env_checklist.head(10))\n",
    "print(env_checklist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "045620f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cell_id              x             y  elevation_mean  elevation_sd  \\\n",
      "0        2 -227623.701670  71016.284889      633.591003     48.028278   \n",
      "1        3 -224632.022042  71016.284889      556.442810     51.946083   \n",
      "2        4 -221640.342413  71016.284889      528.164001     43.113594   \n",
      "3        5 -218648.662784  71016.284889      609.500244     79.011230   \n",
      "4        6 -215656.983155  71016.284889      720.016785     76.634804   \n",
      "5        7 -212665.303527  71016.284889      777.005615     44.189632   \n",
      "6        8 -209673.623898  71016.284889      786.669800     60.027111   \n",
      "7        9 -206681.944269  71016.284889      816.645874     54.481831   \n",
      "8       10 -203690.264640  71016.284889      782.974854     60.780556   \n",
      "9       11 -200698.585012  71016.284889      716.187378     38.633827   \n",
      "\n",
      "   ed_c00_water  pland_c00_water  ed_c01_evergreen_needleleaf  \\\n",
      "0           0.0              0.0                          0.0   \n",
      "1           0.0              0.0                          0.0   \n",
      "2           0.0              0.0                          0.0   \n",
      "3           0.0              0.0                          0.0   \n",
      "4           0.0              0.0                          0.0   \n",
      "5           0.0              0.0                          0.0   \n",
      "6           0.0              0.0                          0.0   \n",
      "7           0.0              0.0                          0.0   \n",
      "8           0.0              0.0                          0.0   \n",
      "9           0.0              0.0                          0.0   \n",
      "\n",
      "   pland_c01_evergreen_needleleaf  ed_c02_evergreen_broadleaf  ...  \\\n",
      "0                             0.0                           0  ...   \n",
      "1                             0.0                           0  ...   \n",
      "2                             0.0                           0  ...   \n",
      "3                             0.0                           0  ...   \n",
      "4                             0.0                           0  ...   \n",
      "5                             0.0                           0  ...   \n",
      "6                             0.0                           0  ...   \n",
      "7                             0.0                           0  ...   \n",
      "8                             0.0                           0  ...   \n",
      "9                             0.0                           0  ...   \n",
      "\n",
      "   ed_c10_grassland  pland_c10_grassland  ed_c12_cropland  pland_c12_cropland  \\\n",
      "0          0.415071             0.641026         0.553428            0.641026   \n",
      "1          0.542986             0.628931         0.000000            0.000000   \n",
      "2          2.352069             3.205128         0.000000            0.000000   \n",
      "3          2.307691             3.773585         0.000000            0.000000   \n",
      "4          0.278499             0.645161         0.556999            0.645161   \n",
      "5          0.276714             0.641026         0.553428            0.641026   \n",
      "6          0.814479             1.257862         1.357465            2.515723   \n",
      "7          0.553428             0.641026         0.691785            1.282051   \n",
      "8          5.764589            11.801242         4.960228            8.695652   \n",
      "9          7.147847            19.480519         5.606154            9.090909   \n",
      "\n",
      "   ed_c13_urban  pland_c13_urban  ed_c15_nonvegetated  pland_c15_nonvegetated  \\\n",
      "0           0.0              0.0                  0.0                     0.0   \n",
      "1           0.0              0.0                  0.0                     0.0   \n",
      "2           0.0              0.0                  0.0                     0.0   \n",
      "3           0.0              0.0                  0.0                     0.0   \n",
      "4           0.0              0.0                  0.0                     0.0   \n",
      "5           0.0              0.0                  0.0                     0.0   \n",
      "6           0.0              0.0                  0.0                     0.0   \n",
      "7           0.0              0.0                  0.0                     0.0   \n",
      "8           0.0              0.0                  0.0                     0.0   \n",
      "9           0.0              0.0                  0.0                     0.0   \n",
      "\n",
      "   ed_c255_unclassified  pland_c255_unclassified  \n",
      "0                     0                        0  \n",
      "1                     0                        0  \n",
      "2                     0                        0  \n",
      "3                     0                        0  \n",
      "4                     0                        0  \n",
      "5                     0                        0  \n",
      "6                     0                        0  \n",
      "7                     0                        0  \n",
      "8                     0                        0  \n",
      "9                     0                        0  \n",
      "\n",
      "[10 rows x 35 columns]\n",
      "(2787, 35)\n"
     ]
    }
   ],
   "source": [
    "print(env_prediction_grid.head(10))\n",
    "print(env_prediction_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f34b7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  119  120  121  122  \\\n",
      "0  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "1  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "2  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "3  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "4  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "5  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "6  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "7  NaN  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "8  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "9  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "\n",
      "   123  124  125  126  127  128  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "5  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "6  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "7  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "8  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "9  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[10 rows x 129 columns]\n",
      "(66, 129)\n"
     ]
    }
   ],
   "source": [
    "print(prediction_grid.head(10))\n",
    "print(prediction_grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa1ac7",
   "metadata": {},
   "source": [
    "## Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4816367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'num_layers': [2, 3, 4, 5, 6], \n",
    "    'dropout_rate': [0, 0.1, 0.2], \n",
    "    'learning_rate': [0.01, 0.005, 0.001],\n",
    "    'num_conv': [2, 4, 6], \n",
    "    'kernelsize': [2, 3, 4, 5], \n",
    "    'pad': [0, 1, 2], \n",
    "    'stride_len': [1, 2], \n",
    "    # 'input_dim': 2, \n",
    "    'hidden_dim': [64, 128, 256, 512, 1024], \n",
    "    # 'output_dim': 1, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5864628",
   "metadata": {},
   "source": [
    "## Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd02166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "junco_data = pd.merge(checklist_zf, env_checklist, how = 'outer', left_index = True, right_index = True)\n",
    "junco_data.reset_index(inplace=True)\n",
    "junco_data.drop(labels = ['checklist_id', 'observer_id', 'type'], axis = 1, inplace = True)\n",
    "# junco_shape = junco_data.shape[0]\n",
    "# np.reshape(junco_data, shape = [junco_shape, junco_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69ef096b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U32')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUFuncTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m junco_data.iterrows():\n\u001b[32m     29\u001b[39m     i, j = row[\u001b[33m'\u001b[39m\u001b[33mlat_bin\u001b[39m\u001b[33m'\u001b[39m], row[\u001b[33m'\u001b[39m\u001b[33mlon_bin\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     counts[i, j] += \u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n",
      "\u001b[31mUFuncTypeError\u001b[39m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U32')) -> None"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "grid_size = (junco_data['latitude'].nunique(), junco_data['longitude'].nunique())  # height, width\n",
    "features = junco_data.columns\n",
    "\n",
    "# Get bounds\n",
    "lat_min, lat_max = junco_data['latitude'].min(), junco_data['latitude'].max()\n",
    "lon_min, lon_max = junco_data['longitude'].min(), junco_data['longitude'].max()\n",
    "\n",
    "# Create bins\n",
    "lat_bins = np.linspace(lat_min, lat_max, grid_size[0] + 1)\n",
    "lon_bins = np.linspace(lon_min, lon_max, grid_size[1] + 1)\n",
    "\n",
    "# Digitize coordinates into bins\n",
    "junco_data['lat_bin'] = np.digitize(junco_data['latitude'], lat_bins) - 1\n",
    "junco_data['lon_bin'] = np.digitize(junco_data['longitude'], lon_bins) - 1\n",
    "\n",
    "# Clip to avoid out-of-bounds\n",
    "junco_data['lat_bin'] = junco_data['lat_bin'].clip(0, grid_size[0] - 1)\n",
    "junco_data['lon_bin'] = junco_data['lon_bin'].clip(0, grid_size[1] - 1)\n",
    "\n",
    "# Initialize grid tensor\n",
    "grid = np.zeros((grid_size[0], grid_size[1], len(features)))\n",
    "\n",
    "# Count how many points in each cell for averaging\n",
    "counts = np.zeros((grid_size[0], grid_size[1]))\n",
    "\n",
    "# Fill the grid with mean feature values\n",
    "for _, row in junco_data.iterrows():\n",
    "    i, j = row['lat_bin'], row['lon_bin']\n",
    "    grid[i, j] += np.array([row[f] for f in features])\n",
    "    counts[i, j] += 1\n",
    "\n",
    "# Avoid division by zero\n",
    "nonzero_mask = counts > 0\n",
    "grid[nonzero_mask] /= counts[nonzero_mask, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4544d86",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73029efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_dim(input_dim, pad, kernelsize, stride_len):\n",
    "    return ((input_dim + (2*pad) - kernelsize) / stride_len) + 1\n",
    "\n",
    "def pool_dim(input_dim, kernelsize, stride_len):\n",
    "    return ((input_dim - kernelsize) / stride_len) + 1\n",
    "\n",
    "class birdNN(nn.Module):\n",
    "    def __init__(self, num_layers, dropout_rate, \n",
    "                 num_conv, kernelsize, pad, stride_len, \n",
    "                 input_dim, hidden_dim, output_dim):\n",
    "        super(birdNN, self).__init__()\n",
    "        ## Convolution Layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(nn.Conv2d(input_dim, 16, \n",
    "                                          kernel_size = kernelsize, stride = stride_len, \n",
    "                                          padding = pad))\n",
    "        conv_size = conv_dim(input_dim, pad, kernelsize, stride_len)\n",
    "        print(conv_size)\n",
    "        for _ in range(num_conv):\n",
    "            self.conv_layers.append(nn.Conv2d(16, 16, \n",
    "                                          kernel_size = kernelsize, stride = stride_len, \n",
    "                                          padding = pad))\n",
    "            conv_size = conv_dim(conv_size, pad, kernelsize, stride_len)\n",
    "            print(conv_size)\n",
    "        self.conv_layers.append(nn.Conv2d(16, 32, \n",
    "                                          kernel_size = kernelsize, stride = stride_len, \n",
    "                                          padding = pad))\n",
    "        conv_size = conv_dim(conv_size, pad, kernelsize, stride_len)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = kernelsize, stride = stride_len)\n",
    "        pool_size = pool_dim(conv_size, kernelsize, stride_len)\n",
    "        print(pool_size)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.activation = nn.LeakyReLU(0.01)\n",
    "        if not dropout_rate:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "        ## Dense Layers\n",
    "        self.input_fc = nn.Linear(int(32 * pool_size * pool_size), hidden_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append(nn.LeakyReLU(0.01))\n",
    "            if not dropout_rate:\n",
    "                self.layers.append(nn.Dropout(dropout_rate))\n",
    "        self.output_fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = self.activation(conv_layer(x))\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout(x)\n",
    "        # x = self.pool(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.activation(self.input_fc(x))\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_fc(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca5631",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f2ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "46.0\n",
      "45.0\n",
      "44.0\n",
      "42.0\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "23.5\n",
      "11.75\n",
      "5.875\n",
      "1.46875\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n",
      "Starting Model Training\n",
      "48.0\n",
      "49.0\n",
      "50.0\n",
      "50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m trainloader = DataLoader(train_subset, batch_size = batchsize, shuffle = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m testloader = DataLoader(test_subset, batch_size = batchsize, shuffle = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m model = \u001b[43mbirdNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m               \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m               \u001b[49m\u001b[43mnum_conv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernelsize\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernelsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_len\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m               \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m criterion = nn.CrossEntropyLoss()\n\u001b[32m     24\u001b[39m accuracy = metrics.MulticlassAccuracy(num_classes = num_classes)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mbirdNN.__init__\u001b[39m\u001b[34m(self, num_layers, dropout_rate, num_conv, kernelsize, pad, stride_len, input_dim, hidden_dim, output_dim)\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mself\u001b[39m.dropout = nn.Dropout(dropout_rate)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m## Dense Layers\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28mself\u001b[39m.input_fc = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.layers = nn.ModuleList()\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:112\u001b[39m, in \u001b[36mLinear.__init__\u001b[39m\u001b[34m(self, in_features, out_features, bias, device, dtype)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_parameter(\u001b[33m\"\u001b[39m\u001b[33mbias\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:118\u001b[39m, in \u001b[36mLinear.reset_parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[43minit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    120\u001b[39m         fan_in, _ = init._calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m.weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\init.py:518\u001b[39m, in \u001b[36mkaiming_uniform_\u001b[39m\u001b[34m(tensor, a, mode, nonlinearity, generator)\u001b[39m\n\u001b[32m    516\u001b[39m bound = math.sqrt(\u001b[32m3.0\u001b[39m) * std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 0\n",
    "num_classes = 2\n",
    "num_features = junco_data.shape[1] - 1\n",
    "folds = 5\n",
    "results = {}\n",
    "batchsize = 10\n",
    "kfold = model_selection.KFold(n_splits = folds, shuffle = True)\n",
    "for params in itertools.product(*parameter_grid.values()):\n",
    "    num_layers, dropout_rate, learning_rate, num_conv, kernelsize, pad, stride_len, hidden_dim = params\n",
    "    scores = []\n",
    "    for folds, (train_index, test_index) in enumerate(kfold.split(junco_data)):\n",
    "        train_subset = torch.utils.data.Subset(junco_data, train_index)\n",
    "        test_subset = torch.utils.data.Subset(junco_data, test_index)\n",
    "        \n",
    "        trainloader = DataLoader(train_subset, batch_size = batchsize, shuffle = True)\n",
    "        testloader = DataLoader(test_subset, batch_size = batchsize, shuffle = True)\n",
    "\n",
    "        model = birdNN(input_dim = num_features, output_dim = num_classes,\n",
    "                       num_layers = num_layers, dropout_rate = dropout_rate, \n",
    "                       num_conv = num_conv, kernelsize = kernelsize, pad = pad, stride_len = stride_len, \n",
    "                       hidden_dim = hidden_dim\n",
    "                )\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        accuracy = metrics.MulticlassAccuracy(num_classes = num_classes)\n",
    "        auroc = metrics.MulticlassAUROC(num_classes = num_classes)\n",
    "        # confusion_matrix = metrics.functional.multiclass_confusion_matrix\n",
    "        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma  = 0.75)\n",
    "\n",
    "        print(\"Starting Model Training\")\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        train_auroc = []\n",
    "\n",
    "        test_accuracy = []\n",
    "        test_auroc = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            ## Model Training\n",
    "            running_loss = 0\n",
    "            for inputs, presence in trainloader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, presence)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                accuracy.update(outputs, presence)\n",
    "                auroc.update(outputs, presence)\n",
    "            train_accuracy.append(accuracy.compute().numpy())\n",
    "            train_auroc.append(accuracy.compute().numpy())\n",
    "            train_loss.append(running_loss)\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch: {epoch + 1}\\n')\n",
    "                print(f'Loss: {train_loss[epoch]}\\n')\n",
    "                print(f'Accuracy: {train_accuracy[epoch]}\\n')\n",
    "                print(f'AUROC: {train_auroc[epoch]}\\n')\n",
    "\n",
    "            ## Model Validation\n",
    "            accuracy.reset()\n",
    "            auroc.reset()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, presence in testloader:\n",
    "                    outputs = model(inputs)\n",
    "                    accuracy.update(outputs, presence)\n",
    "                    auroc.update(outputs, presence)\n",
    "            \n",
    "            test_accuracy.append(accuracy.compute().numpy())\n",
    "            test_auroc.append(auroc.compute().numpy())\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Test Accuracy: {test_accuracy[epoch]}\\n')\n",
    "                print(f'Test AUROC: {test_auroc[epoch]}\\n')\n",
    "            \n",
    "\n",
    "            scores.append(accuracy)\n",
    "            accuracy.reset()\n",
    "            auroc.reset()\n",
    "            model.train()\n",
    "\n",
    "            ## Saves model state\n",
    "            torch.save(model.state_dict, f'./model_states/model_{folds}.pth')\n",
    "    avg_score = np.mean(scores)\n",
    "    results[params] = avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be0c18",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78c904",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m X = junco_data.drop(columns=[\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 'species_observed', \u001b[39;00m\n\u001b[32m      3\u001b[39m                                           \u001b[33m'\u001b[39m\u001b[33mstate_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlocality_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprotocol_type\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mall_species_reported\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mobservation_date\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m                                           ]).values\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# y = junco_data['species_observed'].values\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Parameters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m grid_size = (\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatitude\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.nunique(), X[\u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m].nunique())  \u001b[38;5;66;03m# height, width\u001b[39;00m\n\u001b[32m     10\u001b[39m features = X.columns\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Get bounds\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "X = junco_data.drop(columns=[\n",
    "    # 'species_observed', \n",
    "                                          'state_code', 'locality_id', 'protocol_type', 'all_species_reported', 'observation_date'\n",
    "                                          ]).values\n",
    "# y = junco_data['species_observed'].values\n",
    "\n",
    "\n",
    "# Parameters\n",
    "grid_size = (X['latitude'].nunique(), X['longitude'].nunique())  # height, width\n",
    "features = X.columns\n",
    "\n",
    "# Get bounds\n",
    "lat_min, lat_max = X['latitude'].min(), X['latitude'].max()\n",
    "lon_min, lon_max = X['longitude'].min(), X['longitude'].max()\n",
    "\n",
    "# Create bins\n",
    "lat_bins = np.linspace(lat_min, lat_max, grid_size[0] + 1)\n",
    "lon_bins = np.linspace(lon_min, lon_max, grid_size[1] + 1)\n",
    "\n",
    "# Digitize coordinates into bins\n",
    "X['lat_bin'] = np.digitize(X['latitude'], lat_bins) - 1\n",
    "X['lon_bin'] = np.digitize(X['longitude'], lon_bins) - 1\n",
    "\n",
    "# Clip to avoid out-of-bounds\n",
    "X['lat_bin'] = X['lat_bin'].clip(0, grid_size[0] - 1)\n",
    "X['lon_bin'] = X['lon_bin'].clip(0, grid_size[1] - 1)\n",
    "\n",
    "# Initialize grid tensor\n",
    "grid = np.zeros((grid_size[0], grid_size[1], len(features)))\n",
    "\n",
    "# Count how many points in each cell for averaging\n",
    "counts = np.zeros((grid_size[0], grid_size[1]))\n",
    "\n",
    "# Fill the grid with mean feature values\n",
    "for _, row in junco_data.iterrows():\n",
    "    i, j = row['lat_bin'], row['lon_bin']\n",
    "    grid[i, j] += np.array([row[f] for f in features])\n",
    "    counts[i, j] += 1\n",
    "\n",
    "# Avoid division by zero\n",
    "nonzero_mask = counts > 0\n",
    "grid[nonzero_mask] /= counts[nonzero_mask, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0327dbe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatitude\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.nunique()\n",
      "\u001b[31mIndexError\u001b[39m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "X['latitude'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18143e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n",
      "42.0\n",
      "42.0\n",
      "42.0\n",
      "42.0\n",
      "40.0\n",
      "Starting Model Training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [32, 42]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, presence \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[32m     46\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     loss = criterion(outputs, presence)\n\u001b[32m     49\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mbirdNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m conv_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.conv_layers:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.activation(\u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     49\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.pool(x)\n\u001b[32m     50\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [32, 42]"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "num_classes = 2\n",
    "\n",
    "batchsize = 32\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "X = torch.tensor(junco_data.drop(columns=['species_observed', \n",
    "                                          'state_code', 'locality_id', 'protocol_type', 'all_species_reported', 'observation_date'\n",
    "                                          ]).values, dtype=torch.float32)\n",
    "y = torch.tensor(junco_data['species_observed'].values, dtype=torch.long)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "num_features = X.shape[1]\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "trainloader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "\n",
    "# trainloader = DataLoader(junco_data, batch_size = batchsize, shuffle = True)\n",
    "# testloader = DataLoader(junco_data, batch_size = batchsize, shuffle = True)\n",
    "\n",
    "model = birdNN(input_dim = num_features, output_dim = num_classes,\n",
    "               num_layers = 4, dropout_rate = 0.2, \n",
    "               num_conv = 4, kernelsize = 3, pad = 1, stride_len = 1, \n",
    "               hidden_dim = 64\n",
    "        )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracy = metrics.MulticlassAccuracy(num_classes = num_classes)\n",
    "auroc = metrics.MulticlassAUROC(num_classes = num_classes)\n",
    "    # confusion_matrix = metrics.functional.multiclass_confusion_matrix\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma  = 0.75)\n",
    "print(\"Starting Model Training\")\n",
    "model.train()\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "train_auroc = []\n",
    "test_accuracy = []\n",
    "test_auroc = []\n",
    "for epoch in range(epochs):\n",
    "    ## Model Training\n",
    "    running_loss = 0\n",
    "    for inputs, presence in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, presence)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        accuracy.update(outputs, presence)\n",
    "        auroc.update(outputs, presence)\n",
    "    train_accuracy.append(accuracy.compute().numpy())\n",
    "    train_auroc.append(auroc.compute().numpy())\n",
    "    train_loss.append(running_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch: {epoch + 1}\\n')\n",
    "        print(f'Loss: {train_loss[epoch]}\\n')\n",
    "        print(f'Accuracy: {train_accuracy[epoch]}\\n')\n",
    "        print(f'AUROC: {train_auroc[epoch]}\\n')\n",
    "    ## Model Validation\n",
    "    accuracy.reset()\n",
    "    auroc.reset()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, presence in testloader:\n",
    "            outputs = model(inputs)\n",
    "            accuracy.update(outputs, presence)\n",
    "            auroc.update(outputs, presence)\n",
    "    \n",
    "    test_accuracy.append(accuracy.compute().numpy())\n",
    "    test_auroc.append(auroc.compute().numpy())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Test Accuracy: {test_accuracy[epoch]}\\n')\n",
    "        print(f'Test AUROC: {test_auroc[epoch]}\\n')\n",
    "    \n",
    "    scores.append(accuracy)\n",
    "    accuracy.reset()\n",
    "    auroc.reset()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e87021ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "978",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 978",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpresence\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alonz\\OneDrive\\George Washington University\\Spring 2025\\STAT 6260 Statistical Deep Learning\\Final\\birdCNN\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 978"
     ]
    }
   ],
   "source": [
    "for inputs, presence in trainloader:\n",
    "    print(inputs)\n",
    "    print(presence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
